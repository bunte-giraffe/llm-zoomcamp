{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a814a22-9f44-4398-b471-b112ed4aa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d16531-669a-41c1-9698-c2c2b5486874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        contents=prompt\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c16537-70a9-46e8-a511-8b66cfe89e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5e9bf9-e652-4181-93dc-f37af8596e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba817f6-086d-477c-9bb4-210a63105a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '7b385051d6db', 'cluster_name': 'docker-cluster', 'cluster_uuid': '0Wnl4O2hSFexy0_4Q1m43A', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b28b4ff-6bc1-4bb5-993b-46a2a26950b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11790b6e-1e40-42d4-a9ea-c823834ab0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions-4'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install requests\n",
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index_name = \"course-questions-4\"\n",
    "\n",
    "es_client.indices.create(index=index_name, settings=index_settings['settings'], mappings=index_settings['mappings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5368f935-50bc-4635-a02a-73731c1d27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!pip install tqdm\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac2b467-6239-4f91-9568-9474b492879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [00:02<00:00, 412.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005c5bc6-dbde-4db6-baaf-121220c3d0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.50556"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def elastic_search_max_score(query):\n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name, size=search_query['size'], query=search_query['query'])\n",
    "    result_scores = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_scores.append(hit['_score'])\n",
    "    return max(result_scores)\n",
    "\n",
    "elastic_search_max_score('How do execute a command on a Kubernetes pod?')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cb019ee-cb8d-448b-b4e5-5962ede933a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = es_client.search(index=index_name, size=search_query['size'], query=search_query['query'])\n",
    "    result_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    return result_docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721f08a7-153d-46f4-a39b-5167da7ff88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I debug a docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from my local machine to docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search('How do copy a file to a Docker container?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40739248-6057-4b61-b934-8c5f155c869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446\n"
     ]
    }
   ],
   "source": [
    "query = \"How do copy a file to a Docker container?\"\n",
    "search_results = elastic_search(query)\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "        context = context + context_template.format(question=doc['question'], text=doc['text']) + \"\\n\\n\"\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "prompt = build_prompt(query, search_results)\n",
    "print(len(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aee3f80-d1a4-4721-b14c-7bf1b5f1b47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: CountTokensResult(total_tokens=353)\n",
      "Encoded tokens: PreviewComputeTokensResult(tokens_info=[TokensInfo(token_ids=[2045, 235303, 478, 476, 3205, 10649, 20409, 235265, 10358, 573, 58470, 3482, 611, 573, 148990, 774, 573, 22217, 8746, 235265, 108, 7056, 1297, 573, 10275, 774, 573, 148990, 1185, 39534, 573, 58470, 235265, 109, 53118, 235292, 2250, 749, 5469, 476, 2482, 577, 476, 60541, 11254, 235336, 109, 71157, 235292, 108, 235368, 235292, 2250, 749, 590, 24391, 476, 54742, 11254, 235336, 108, 235280, 235292, 37181, 573, 11254, 2416, 575, 29295, 4058, 578, 135522, 573, 7929, 3371, 235269, 712, 674, 665, 11207, 476, 41912, 5017, 235265, 108, 38584, 2060, 728, 500, 3297, 9203, 3371, 41912, 968, 2502, 235313, 108, 2495, 573, 11254, 603, 3303, 5327, 235269, 17991, 476, 5017, 575, 573, 3724, 11254, 235292, 108, 38584, 9516, 591, 3655, 573, 11254, 235290, 539, 235275, 108, 38584, 15287, 728, 500, 968, 7139, 235290, 539, 235313, 41912, 108, 235278, 107749, 595, 37661, 235275, 109, 235368, 235292, 2250, 749, 590, 5469, 6630, 774, 970, 2813, 6479, 577, 54742, 11254, 235336, 108, 235280, 235292, 1646, 798, 5469, 6630, 774, 861, 2813, 6479, 1280, 476, 60541, 11254, 2177, 573, 54742, 23959, 5017, 235265, 5698, 235303, 235256, 1368, 577, 749, 665, 235292, 108, 1469, 5469, 476, 2482, 689, 15670, 774, 861, 2813, 6479, 1280, 476, 5327, 60541, 11254, 235269, 692, 798, 1281, 573, 4103, 38584, 23959, 5017, 27271, 714, 6859, 36412, 603, 685, 6397, 235292, 108, 38584, 23959, 1148, 2222, 235283, 511, 235283, 5047, 235283, 1716, 235298, 483, 235298, 27079, 11254, 235298, 539, 27744, 2222, 235283, 473, 235283, 7139, 108, 235314, 101972, 1084, 29232, 2009, 40032, 109, 235368, 235292, 2250, 749, 590, 5469, 6630, 774, 476, 2167, 15173, 1280, 54742, 11254, 235349, 235256, 3434, 15670, 235336, 108, 235280, 235292, 1646, 798, 5469, 6630, 774, 861, 2813, 6479, 1280, 476, 60541, 11254, 2177, 573, 54742, 23959, 5017, 235265, 5698, 235303, 235256, 1368, 577, 749, 665, 235292, 108, 886, 573, 60541, 1716, 235269, 692, 798, 3658, 573, 15173, 10751, 573, 6630, 674, 692, 1938, 577, 5469, 1163, 235265, 714, 6859, 36412, 603, 685, 6397, 235292, 108, 57225, 10890, 5379, 235283, 33475, 235265, 2158, 824, 664, 8171, 235283, 235297, 7484, 235298, 2516, 235265, 3049, 824, 11509, 4437, 255978, 4929, 10566, 17537, 653, 43623, 10812], tokens=[b'You', b\"'\", b're', b' a', b' course', b' teaching', b' assistant', b'.', b' Answer', b' the', b' QUESTION', b' based', b' on', b' the', b' CONTEXT', b' from', b' the', b' FAQ', b' database', b'.', b'\\n', b'Use', b' only', b' the', b' facts', b' from', b' the', b' CONTEXT', b' when', b' answering', b' the', b' QUESTION', b'.', b'\\n\\n', b'QUESTION', b':', b' How', b' do', b' copy', b' a', b' file', b' to', b' a', b' Docker', b' container', b'?', b'\\n\\n', b'CONTEXT', b':', b'\\n', b'Q', b':', b' How', b' do', b' I', b' debug', b' a', b' docker', b' container', b'?', b'\\n', b'A', b':', b' Launch', b' the', b' container', b' image', b' in', b' interactive', b' mode', b' and', b' overriding', b' the', b' entry', b'point', b',', b' so', b' that', b' it', b' starts', b' a', b' bash', b' command', b'.', b'\\n', b'docker', b' run', b' -', b'it', b' --', b'entry', b'point', b' bash', b' <', b'image', b'>', b'\\n', b'If', b' the', b' container', b' is', b' already', b' running', b',', b' execute', b' a', b' command', b' in', b' the', b' specific', b' container', b':', b'\\n', b'docker', b' ps', b' (', b'find', b' the', b' container', b'-', b'id', b')', b'\\n', b'docker', b' exec', b' -', b'it', b' <', b'container', b'-', b'id', b'>', b' bash', b'\\n', b'(', b'Marcos', b' M', b'JD', b')', b'\\n\\n', b'Q', b':', b' How', b' do', b' I', b' copy', b' files', b' from', b' my', b' local', b' machine', b' to', b' docker', b' container', b'?', b'\\n', b'A', b':', b' You', b' can', b' copy', b' files', b' from', b' your', b' local', b' machine', b' into', b' a', b' Docker', b' container', b' using', b' the', b' docker', b' cp', b' command', b'.', b' Here', b\"'\", b's', b' how', b' to', b' do', b' it', b':', b'\\n', b'To', b' copy', b' a', b' file', b' or', b' directory', b' from', b' your', b' local', b' machine', b' into', b' a', b' running', b' Docker', b' container', b',', b' you', b' can', b' use', b' the', b' `', b'docker', b' cp', b' command', b'`.', b' The', b' basic', b' syntax', b' is', b' as', b' follows', b':', b'\\n', b'docker', b' cp', b' /', b'path', b'/', b'to', b'/', b'local', b'/', b'file', b'_', b'or', b'_', b'directory', b' container', b'_', b'id', b':/', b'path', b'/', b'in', b'/', b'container', b'\\n', b'H', b'rith', b'ik', b' Kumar', b' Ad', b'vani', b'\\n\\n', b'Q', b':', b' How', b' do', b' I', b' copy', b' files', b' from', b' a', b' different', b' folder', b' into', b' docker', b' container', b'\\xe2\\x80\\x99', b's', b' working', b' directory', b'?', b'\\n', b'A', b':', b' You', b' can', b' copy', b' files', b' from', b' your', b' local', b' machine', b' into', b' a', b' Docker', b' container', b' using', b' the', b' docker', b' cp', b' command', b'.', b' Here', b\"'\", b's', b' how', b' to', b' do', b' it', b':', b'\\n', b'In', b' the', b' Docker', b'file', b',', b' you', b' can', b' provide', b' the', b' folder', b' containing', b' the', b' files', b' that', b' you', b' want', b' to', b' copy', b' over', b'.', b' The', b' basic', b' syntax', b' is', b' as', b' follows', b':', b'\\n', b'COPY', b' [\"', b'src', b'/', b'predict', b'.', b'py', b'\",', b' \"', b'models', b'/', b'x', b'gb', b'_', b'model', b'.', b'bin', b'\",', b' \"./', b'\"]', b'\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t', b'Go', b'pak', b'umar', b' G', b'opin', b'athan'], role='user')])\n"
     ]
    }
   ],
   "source": [
    "from vertexai.preview import tokenization\n",
    "\n",
    "model_name = \"gemini-1.5-flash-001\"\n",
    "tokenizer = tokenization.get_tokenizer_for_model(model_name)\n",
    "\n",
    "result = tokenizer.compute_tokens(prompt)\n",
    "len_result = tokenizer.count_tokens(prompt)\n",
    "\n",
    "print(f\"Token count: {len_result}\")\n",
    "print(f\"Encoded tokens: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307af91-6108-4eb9-8df9-702081cea516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb379a-ac0d-466c-8863-3bb0c0310bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5d02b-f74e-4019-90c9-0679e6eb5d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
