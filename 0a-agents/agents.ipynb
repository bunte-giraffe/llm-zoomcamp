{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc368288",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import minsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd0825d-612a-4cb3-81a0-322c687e4f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983969ae-93a3-43b6-b05f-314d89f28ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x714ff62e60f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1139dfeb-c9bf-4f86-bc40-a45bbb7c690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76aed4ab-bcfd-472e-93e8-214f29443f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "search_results = search('I just discovered the course. Can I join now?')\n",
    "print(search_results[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5be1479d-141f-474f-b49b-217105d72b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from google.genai import types\n",
    "\n",
    "gemini_client = genai.Client()\n",
    "def llm(prompt):\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        contents=prompt\n",
    "    )\n",
    "    response = response.text.replace(\"```json\",\"\").replace(\"```\", \"\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c40538-9725-4746-8a79-a76f8f667d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d11b6f-959c-4334-89c2-c049bbb53cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered the course. Can I join now?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90c9a1d7-4b3d-437b-ba7d-7ce6d74d99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3904e91-63dd-4e5e-8d74-f06890979b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can join the course even if you don't register. You're still eligible to submit the homework.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7166f7-ba19-4fbf-a890-1ec4ef1fde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f2e4b33-8f45-41f6-ad66-9abd18f4eb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b205049e-06a1-458e-bb7f-d0816ebfb8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you encounter a `kafka.errors.NoBrokersAvailable: NoBrokersAvailable` error, it's likely that your Kafka broker Docker container isn't working. You can use `docker ps` to confirm. Then, navigate to the Docker Compose YAML file folder and run `docker compose up -d` to start all the instances.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('How do I run Kafka in Docker?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c4f845-d758-4e5c-b3c5-417d6943c2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sorry, but I cannot answer this question because the provided context is empty.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('How do I patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "422c219d-edae-49e1-8fa4-23d5f796cb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patching KDE under FreeBSD can be done in a few ways, depending on what you want to patch. Here\\'s a breakdown of the common scenarios and how to approach them:\\n\\n**1. Patching a Port (Recommended for Most Users)**\\n\\nThis is the most common and generally recommended method. It\\'s suitable for applying patches to KDE components installed via the FreeBSD Ports Collection.\\n\\n*   **Identify the Port:** First, identify the specific KDE port you need to patch.  Let\\'s say you need to patch `kde-frameworks/kio`.\\n\\n*   **Find the Port Directory:** Navigate to the port\\'s directory within the Ports Collection.  This is typically under `/usr/ports`.\\n\\n    bash\\n    cd /usr/ports/kde-frameworks/kio\\n    \\n\\n*   **Obtain the Patch:** Get the patch file.  This might come from:\\n    *   A bug report on the KDE bug tracker (bugs.kde.org)\\n    *   A mailing list related to FreeBSD ports or KDE\\n    *   From the FreeBSD Bugzilla\\n    *   Directly from the upstream KDE developers\\n    *   Your own modifications to the source code\\n\\n    Assume you have a patch file named `kio.patch` in your current directory.\\n\\n*   **Apply the Patch:** Use the `patch` command:\\n\\n    bash\\n    patch -p1 < kio.patch\\n    \\n\\n    *   `-p1`:  This option tells `patch` to remove the first component of the path specified in the patch file.  It\\'s almost always what you want when applying patches to ports.\\n    *   `kio.patch`:  The name of your patch file.\\n\\n    **Important:**  Carefully examine the output of the `patch` command.  It will tell you if the patch applied successfully, or if there were any errors or \"hunks failed\" (meaning parts of the patch couldn\\'t be applied cleanly).\\n\\n    If you encounter errors:\\n    *   **Check the Context:** The patch might be for a slightly different version of the code.  Read the patch file to see what files and lines it\\'s trying to modify.\\n    *   **Manual Application:**  If the patch can\\'t be applied cleanly, you might need to manually edit the files the patch is intended to modify.  This requires some understanding of the code and the changes the patch is trying to make.\\n\\n*   **Rebuild the Port:** After successfully applying the patch, rebuild and reinstall the port:\\n\\n    bash\\n    make clean\\n    make\\n    sudo make install\\n    \\n\\n    *   `make clean`: Removes any previously compiled files.\\n    *   `make`: Compiles the port.\\n    *   `sudo make install`: Installs the compiled files with root privileges.\\n\\n    If you had to manually edit any files, you might want to also run `make deinstall` and `make reinstall` to ensure everything is properly installed.\\n\\n*   **Test:** Thoroughly test the patched component to ensure the patch has the desired effect and hasn\\'t introduced any regressions.\\n\\n**2.  Patching Installed Packages (Not Recommended Unless Necessary)**\\n\\nWhile you *can* apply patches directly to files within the installed package directories (usually under `/usr/local`), this is strongly discouraged:\\n\\n*   **Updates Will Overwrite:**  The package management system (pkg) will be unaware of your changes.  If you update the package using `pkg upgrade`, your patch will likely be overwritten.\\n*   **Dependency Issues:**  Modifying files directly can break dependencies or cause conflicts.\\n*   **Difficult to Track:** It becomes very hard to keep track of what changes you\\'ve made, leading to maintenance nightmares.\\n\\n**If you *absolutely must* patch an installed package (e.g., for a quick temporary fix), here\\'s the general idea (but proceed with caution):**\\n\\n*   **Locate the Files:** Identify the exact files within the installed package that need to be patched.  Use `pkg contents <package_name>` to list the files installed by a package.\\n*   **Backup the Files:**  Before making any changes, *always* back up the original files.\\n*   **Apply the Patch:** Use the `patch` command (with the correct `-p` option) to apply the patch to the files in their installed locations.  You\\'ll likely need to use `sudo`.\\n*   **Restart Services:**  If the patched files are part of a running service (like Plasma), you might need to restart the service for the changes to take effect.\\n*   **Document Everything:**  Keep detailed notes about what you changed, which patch you applied, and where the files are located.\\n*   **Consider Rebuilding the Port Instead:** This is still almost always the better approach.\\n\\n**3.  Patching the Source Code Directly (For Developers)**\\n\\nIf you are a KDE developer or want to contribute patches, you\\'ll be working directly with the source code. This typically involves:\\n\\n*   **Git:**  Use Git to clone the KDE repository you\\'re interested in.  For example:\\n\\n    bash\\n    git clone git://anongit.kde.org/kio.git\\n    cd kio\\n    \\n\\n*   **Make Changes:**  Make your code changes.\\n*   **Create a Patch:** Use `git diff` to create a patch file.\\n\\n    bash\\n    git diff > my_kio_fix.patch\\n    \\n\\n*   **Test:** Thoroughly test your changes.\\n*   **Submit the Patch:**  Follow the KDE development guidelines for submitting patches (usually via the KDE bug tracker or a mailing list).\\n\\n**Example: Patching a Configuration File**\\n\\nSometimes, you might need to patch a configuration file.  This is generally simpler:\\n\\n1.  **Locate the Configuration File:** Find the configuration file you want to modify (e.g., in `~/.config` or `/usr/local/etc/kde5/`).\\n2.  **Create a Patch (Optional but Recommended):**\\n    *   Make a copy of the original file (backup).\\n    *   Edit the original file.\\n    *   Use `diff` to create a patch:\\n\\n        bash\\n        diff -u original_file modified_file > my_config_change.patch\\n        \\n\\n3.  **Apply the Patch (If you created one):**\\n\\n        bash\\n        patch < my_config_change.patch\\n        \\n\\n4.  **Test:**  Make sure the changes have the desired effect.\\n\\n**Important Considerations:**\\n\\n*   **Permissions:** When patching files in system directories, you\\'ll likely need to use `sudo` to gain root privileges.\\n*   **Read the Patch:** Before applying any patch, carefully examine its contents. Understand what files it modifies and what changes it makes.  This helps you avoid applying patches that could break your system.\\n*   **Backups:** Always back up files before patching them.  This allows you to easily revert to the original state if something goes wrong.  If using git, you can revert with `git checkout .`\\n*   **Version Compatibility:**  Make sure the patch is intended for the version of the software you are using.  Applying a patch for a different version can lead to errors and instability.\\n*   **Update Ports Tree:** Regularly update your Ports Collection using `portsnap fetch update` to ensure you have the latest versions and patches.\\n*   **Security:** Be cautious when applying patches from untrusted sources.  A malicious patch could compromise your system.\\n\\n**In summary, patching KDE under FreeBSD using the Ports Collection is the safest and most manageable approach for most users. Avoid directly patching installed packages unless absolutely necessary, and always back up your data before making any changes.**\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('How do I patch KDE under FreeBSD?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0fbdf78-46cc-411a-9e02-948cdb9a72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "return response in JSON format.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f2bdb34-259e-4fb5-90c9-0805ecbb356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "How can I run Docker on Windows 10?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "return response in JSON format.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I run Docker on Windows 10?\"\n",
    "context = 'EMPTY'\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48970166-55d0-4e7d-b986-143a7bf63b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbd24418-f775-4606-8f8b-514b0ad36476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"You have a few options for running Docker on Windows 10:\\n\\n1.  **Docker Desktop:** This is the recommended and most common way. Docker Desktop uses WSL 2 (Windows Subsystem for Linux version 2) to run a Linux kernel, which then runs the Docker daemon. This provides excellent performance and integration with Windows.\\n\\n2.  **Docker Toolbox (Legacy):** This is an older method that uses VirtualBox to create a virtual machine running Linux, where Docker runs. Docker Toolbox is generally only recommended for older systems that don't support WSL 2, or for specific edge cases. Docker Desktop is generally preferred.\\n\\nHere's a bit more detail on each:\\n\\n*   **Docker Desktop (Recommended):**\\n    *   **Prerequisites:** Windows 10 64-bit: Home or Pro 2004 (build 19041) or higher, or Enterprise or Education 1703 (build 15063) or higher. Enable WSL 2.\\n    *   **Installation:** Download and install Docker Desktop from the Docker website. During installation, it will prompt you to enable WSL 2 and install a Linux distribution if you haven't already.\\n    *   **Usage:** After installation, Docker Desktop provides a user interface to manage your containers, images, and volumes. You can also use the Docker CLI (command-line interface) in PowerShell or Command Prompt.\\n\\n*   **Docker Toolbox (Legacy):**\\n    *   **Prerequisites:** VirtualBox must be installed.\\n    *   **Installation:** Download and install Docker Toolbox. The installation process sets up the Docker CLI, Docker Machine, and VirtualBox.\\n    *   **Usage:** Docker Toolbox creates a virtual machine (usually named `default`) running a Linux distribution. You need to use Docker Machine to manage the connection to this VM and run Docker commands within it.  You will need to configure your environment to use the Docker Machine.\\n\\nIn most cases, Docker Desktop using WSL 2 is the easiest and most performant solution.  If you encounter issues, ensure virtualization is enabled in your BIOS/UEFI settings.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d378bc27-786b-41e3-88d1-fc57bcc3a65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "return response in JSON format.\n"
     ]
    }
   ],
   "source": [
    "question = \"Can I still join the course?\"\n",
    "context = 'EMPTY'\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03531b60-3df0-4239-abfe-a902681d4978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"Since the context is empty, I need to search for information about course enrollment policies to determine if the student can still join.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67de458a-ce95-40e0-ad6f-02e5d72efd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "430dbc65-dfb4-4e6f-9082-d748c1e52e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': 'Since the context is empty, I need to search for information about course enrollment policies to determine if the student can still join.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ce77513-15ac-43ed-9543-67ab8d3f1039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"Since the context is empty, I need to consult the FAQ or course information to determine if it's still possible to join the course. I don't have enough information to answer this question without further investigation.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "298a90e8-c187-49e2-b5d0-4b972878560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc912b47-a725-432a-957f-9f5c9e4be8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json['action']\n",
    "\n",
    "\n",
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ad451-c32e-46cb-8e00-825ca091760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d28fcc-7c88-43f1-ae8a-a109b9c6d08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8c97ad3-7eb5-4bae-919c-2b5d33d7413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "return response in JSON format.\n"
     ]
    }
   ],
   "source": [
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665c9778-52f6-49f2-aa7e-21ddd4e95b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json= llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3133aa2-79c8-4fae-826a-0734849313a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5883f3d0-68a8-4b08-8a58-b618979dad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7de5975-b94d-4d69-b527-9bcbc5bad9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': \"Since the context is empty, I need to find information about course enrollment policies. I'll search the FAQ to see if there's any information about joining the course after it has started.\"}\n",
      "need to perform search...\n",
      "{'action': 'ANSWER', 'answer': \"Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'source': 'CONTEXT'}\n",
      "{'action': 'ANSWER', 'answer': \"Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'source': 'CONTEXT'}\n"
     ]
    }
   ],
   "source": [
    "print(agentic_rag_v1('Can I still join the course?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "967ebcd8-b3fe-4b80-a7f4-95ba1e0afe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is built with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Return response only in JSON format using the templates provided below. \n",
    "Do not return any other information. \n",
    "Do not use markdown.\n",
    "Do not include any formating in your response (characters like newline character).\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "510ac0e0-bbe0-459b-a44f-14813583f730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is built with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Return response only in JSON format using the templates provided below. \n",
      "Do not return any other information. \n",
      "Do not use markdown.\n",
      "Do not include any formating in your response (characters like newline character).\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "How do I do well on module 1\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "question = 'How do I do well on module 1'\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55127762-6049-4989-83be-ecffb0301b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38337641-370c-436e-833e-cf13e43bf0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The question is very broad. I need to find information regarding specific aspects of Module 1 that can help a student do well. Keywords related to preparation, important concepts, common mistakes, and available resources for Module 1 could be useful.\",\\n\"keywords\": [\"Module 1 preparation tips\", \"Module 1 important concepts\", \"Module 1 common mistakes\", \"Module 1 resources\"]\\n}\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "284d5bb0-e014-4840-8a25-d4879f8e53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6149742-b9f1-4adb-a1f6-a0bfe47992da",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer_json['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e5a0702-92b9-4fb1-b3f1-6ceb8336efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0128f9c-7efb-4b68-b17a-7a959d55df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Module 1 preparation tips',\n",
       " 'Module 1 important concepts',\n",
       " 'Module 1 common mistakes',\n",
       " 'Module 1 resources']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00d3013f-c30b-422f-a8eb-c39238a627f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a5e2d36-3247-4036-a32c-fc45a3a965f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fc4a7ed-f42e-4eb0-b4f9-080103e16f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48f518a0-ef71-4368-871c-8584f477e792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322},\n",
       " {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 112},\n",
       " {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 125},\n",
       " {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 124},\n",
       " {'text': 'Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 377},\n",
       " {'text': 'Cause:\\nIt happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\\nSolution\\nfor updating Windows terminal which worked for me:\\nGo to Microsoft Store.\\nGo to the library of apps installed in your system.\\nSearch for Windows terminal.\\nUpdate the app and restart your system to  see the changes.\\nFor updating the Windows security updates:\\nGo to Windows updates and check if there are any pending updates from Windows, especially security updates.\\nDo restart your system once the updates are downloaded and installed successfully.',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': 'WSL - Insufficient system resources exist to complete the requested service.',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 94}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5fdbc321-153e-4f3c-9501-7cd72da1bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d84e4e41-455a-425e-ae12-40425f5a0c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'action': 'SEARCH',\n",
       "  'reasoning': 'The question is very broad. I need to find information regarding specific aspects of Module 1 that can help a student do well. Keywords related to preparation, important concepts, common mistakes, and available resources for Module 1 could be useful.',\n",
       "  'keywords': ['Module 1 preparation tips',\n",
       "   'Module 1 important concepts',\n",
       "   'Module 1 common mistakes',\n",
       "   'Module 1 resources']}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10b02599-f06f-413f-a917-4943a1fed66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is built with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Return response only in JSON format using the templates provided below. \n",
      "Do not return any other information. \n",
      "Do not use markdown.\n",
      "Do not include any formating in your response (characters like newline character).\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "How do I do well on module 1\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 preparation tips\n",
      "Module 1 important concepts\n",
      "Module 1 common mistakes\n",
      "Module 1 resources\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is very broad. I need to find information regarding specific aspects of Module 1 that can help a student do well. Keywords related to preparation, important concepts, common mistakes, and available resources for Module 1 could be useful.\", \"keywords\": [\"Module 1 preparation tips\", \"Module 1 important concepts\", \"Module 1 common mistakes\", \"Module 1 resources\"]}\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "iteration_number = 1\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "435a471c-3fe0-469e-9fc6-f663576535f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d514cddd-bee5-44f0-bfef-3e355a93b28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n\"action\": \"SEARCH\",\\n\"reasoning\": \"The context provided contains information about errors and solutions related to specific technologies covered in various modules, but it lacks general advice or specific content related to doing well in Module 1. I need to search for more general strategies and topics covered in Module 1 to provide a more helpful answer. The previous search focused on preparation tips, important concepts, common mistakes and resources. I will now refine the search by looking into the specific topics covered in module 1 such as \\'Docker\\' and \\'Terraform\\' and add \\'best practices\\' to the search.\",\\n\"keywords\": [\"Module 1 Docker best practices\", \"Module 1 Terraform best practices\", \"Module 1 topics covered\"]\\n}\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96a95fd0-ec4e-4f0c-a1ad-e8fd048e0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is built with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Return response only in JSON format using the templates provided below. \n",
      "Do not return any other information. \n",
      "Do not use markdown.\n",
      "Do not include any formating in your response (characters like newline character).\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "How do I do well on module 1\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "Module 1 preparation tips\n",
      "Module 1 important concepts\n",
      "Module 1 common mistakes\n",
      "Module 1 resources\n",
      "Module 1 Docker best practices\n",
      "Module 1 Terraform best practices\n",
      "Module 1 topics covered\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Project\n",
      "question: Spark docker - `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You can get the version of py4j from inside docker using this command\n",
      "docker exec -it --user airflow airflow-airflow-scheduler-1 bash -c \"ls /opt/spark/python/lib\"\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\n",
      "answer: When running\n",
      "terraform apply\n",
      "on wsl2 I've got this error:\n",
      "│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\n",
      "│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\n",
      "IT happens because there may be time desync on your machine which affects computing JWT\n",
      "To fix this, run the command\n",
      "sudo hwclock -s\n",
      "which fixes your system time.\n",
      "Reference\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\n",
      "answer: You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?\n",
      "answer: Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error creating Bucket: googleapi: Error 403: Permission denied to access ‘storage.buckets.create’\n",
      "answer: The error:\n",
      "Error: googleapi: Error 403: terraform-trans-campus@trans-campus-410115.iam.gserviceaccount.com does not have storage.buckets.create access to the Google Cloud project. Permission 'storage.buckets.create' denied on resource (or it may not exist)., forbidden\n",
      "The solution:\n",
      "You have to declare the project name as your Project ID, and not your Project name, available on GCP console Dashboard.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is very broad. I need to find information regarding specific aspects of Module 1 that can help a student do well. Keywords related to preparation, important concepts, common mistakes, and available resources for Module 1 could be useful.\", \"keywords\": [\"Module 1 preparation tips\", \"Module 1 important concepts\", \"Module 1 common mistakes\", \"Module 1 resources\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The context provided contains information about errors and solutions related to specific technologies covered in various modules, but it lacks general advice or specific content related to doing well in Module 1. I need to search for more general strategies and topics covered in Module 1 to provide a more helpful answer. The previous search focused on preparation tips, important concepts, common mistakes and resources. I will now refine the search by looking into the specific topics covered in module 1 such as 'Docker' and 'Terraform' and add 'best practices' to the search.\", \"keywords\": [\"Module 1 Docker best practices\", \"Module 1 Terraform best practices\", \"Module 1 topics covered\"]}\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "answer_json = json.loads(answer_json.replace('\\n', ''))\n",
    "keywords = answer_json['keywords']\n",
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)\n",
    "search_results = dedup(search_results)\n",
    "previous_actions.append(answer_json)\n",
    "\n",
    "iteration_number = 2\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "57110048-9ef6-47d4-ad64-8ab2f9a4ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eec8ba1f-b569-4317-9399-3d8f22b0e21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n\"action\": \"ANSWER\",\\n\"answer\": \"Module 1 focuses on Docker and Terraform. To do well, make sure you understand the core concepts of both technologies, including containerization, image building, infrastructure as code, and resource provisioning. Pay close attention to best practices for writing Dockerfiles and Terraform configurations, focusing on security, efficiency, and maintainability. Some common issues in Module 1 include problems with `psycopg2` in Python environments, which can often be resolved by installing or updating the package using `pip install psycopg2-binary`. Also, ensure you are running `terraform init` in the correct directory containing your Terraform configuration files to avoid errors. For Windows users, file system performance can be optimized by storing code within the default Linux distro when using Docker. If you encounter issues with Terraform and JWT tokens on WSL, synchronizing your system time with `sudo hwclock -s` might resolve the problem. Review the provided course materials, and consider practicing with hands-on exercises to reinforce your understanding.\",\\n\"source\": \"OWN_KNOWLEDGE\"\\n}\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a8f6899-a026-47f4-b16b-1d3072402606",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = json.loads(answer_json.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cacd7d7e-209e-4263-99f9-78fea77aa3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 1 focuses on Docker and Terraform. To do well, make sure you understand the core concepts of both technologies, including containerization, image building, infrastructure as code, and resource provisioning. Pay close attention to best practices for writing Dockerfiles and Terraform configurations, focusing on security, efficiency, and maintainability. Some common issues in Module 1 include problems with `psycopg2` in Python environments, which can often be resolved by installing or updating the package using `pip install psycopg2-binary`. Also, ensure you are running `terraform init` in the correct directory containing your Terraform configuration files to avoid errors. For Windows users, file system performance can be optimized by storing code within the default Linux distro when using Docker. If you encounter issues with Terraform and JWT tokens on WSL, synchronizing your system time with `sudo hwclock -s` might resolve the problem. Review the provided course materials, and consider practicing with hands-on exercises to reinforce your understanding.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d683ed27-b10c-48f9-94ba-3d4d54327fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is built with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Return response only in JSON format using the templates provided below. \n",
      "Do not return any other information. \n",
      "Do not use markdown.\n",
      "Do not include any formating in your response (characters like newline character).\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The question is very general: 'what do I need to do to be successful at module 1?' To provide a helpful answer, I need to understand what 'success' means in the context of module 1. This likely involves understanding the learning objectives, assessment criteria, and available resources. Therefore, I will search for information related to module 1's objectives, assessments, and resources.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 objectives\",\n",
      "    \"module 1 assessment\",\n",
      "    \"module 1 resources\",\n",
      "    \"module 1 success tips\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is built with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Return response only in JSON format using the templates provided below. \n",
      "Do not return any other information. \n",
      "Do not use markdown.\n",
      "Do not include any formating in your response (characters like newline character).\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "module 1 assessment\n",
      "module 1 success tips\n",
      "module 1 objectives\n",
      "module 1 resources\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is very general: 'what do I need to do to be successful at module 1?' To provide a helpful answer, I need to understand what 'success' means in the context of module 1. This likely involves understanding the learning objectives, assessment criteria, and available resources. Therefore, I will search for information related to module 1's objectives, assessments, and resources.\", \"keywords\": [\"module 1 objectives\", \"module 1 assessment\", \"module 1 resources\", \"module 1 success tips\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The previous search returned only module-specific error messages from various modules, not general information about Module 1. I need to refine my search to focus on general success strategies, common challenges, and key topics covered in Module 1. I will search for information about the key topics and potential difficulties in Module 1 to provide more specific advice.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 key topics\",\n",
      "    \"module 1 common problems\",\n",
      "    \"module 1 difficulties\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is built with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Return response only in JSON format using the templates provided below. \n",
      "Do not return any other information. \n",
      "Do not use markdown.\n",
      "Do not include any formating in your response (characters like newline character).\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "module 1 assessment\n",
      "module 1 common problems\n",
      "module 1 difficulties\n",
      "module 1 objectives\n",
      "module 1 resources\n",
      "module 1 success tips\n",
      "module 1 key topics\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT Deploy + CI - Location Problems on BigQuery\n",
      "answer: When you are creating the pull request and running the CI, dbt is creating a new schema on BIgQuery. By default that new schema will be created on ‘US’ location, if you have your dataset, schemas and tables on ‘EU’ that will generate an error and the pull request will not be accepted. To change that location to ‘EU’ on the connection to BigQuery from dbt we need to add the location ‘EU’ on the connection optional settings:\n",
      "Dbt -> project -> settings -> connection BIgQuery -> OPtional Settings -> Location -> EU\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - I am having problems with columns datatype while running DBT/BigQuery\n",
      "answer: Issue: If you don’t define the column format while converting from csv to parquet Python will “choose” based on the first rows.\n",
      "✅Solution: Defined the schema while running web_to_gcp.py pipeline.\n",
      "Sebastian adapted the script:\n",
      "https://github.com/sebastian2296/data-engineering-zoomcamp/blob/main/week_4_analytics_engineering/web_to_gcs.py\n",
      "Need a quick change to make the file work with gz files, added the following lines (and don’t forget to delete the file at the end of each iteration of the loop to avoid any problem of disk space)\n",
      "file_name_gz = f\"{service}_tripdata_{year}-{month}.csv.gz\"\n",
      "open(file_name_gz, 'wb').write(r.content)\n",
      "os.system(f\"gzip -d {file_name_gz}\")\n",
      "os.system(f\"rm {file_name_init}.*\")\n",
      "Same ERROR - When running dbt run for fact_trips.sql, the task failed with error:\n",
      "“Parquet column 'ehail_fee' has type DOUBLE which does not match the target cpp_type INT64”\n",
      "开启屏幕阅读器支持\n",
      "要启用屏幕阅读器支持，请按Ctrl+Alt+Z。要了解键盘快捷键，请按Ctrl+斜杠。\n",
      "查找和替换\n",
      "Reason: Parquet files have their own schema. Some parquet files for green data have records with decimals in ehail_fee column.\n",
      "There are some possible fixes:\n",
      "Drop ehail_feel column since it is not really used. For instance when creating a partitioned table from the external table in BigQuery\n",
      "SELECT * EXCEPT (ehail_fee) FROM…\n",
      "Modify stg_green_tripdata.sql model using this line cast(0 as numeric) as ehail_fee.\n",
      "Modify Airflow dag to make the conversion and avoid the error.\n",
      "pv.read_csv(src_file, convert_options=pv.ConvertOptions(column_types = {'ehail_fee': 'float64'}))\n",
      "Same type of ERROR - parquet files with different data types - Fix it with pandas\n",
      "Here is another possibility that could be interesting:\n",
      "You can specify the dtypes when importing the file from csv to a dataframe with pandas\n",
      "pd.from_csv(..., dtype=type_dict)\n",
      "One obstacle is that the regular int64 pandas use (I think this is from the numpy library) does not accept null values (NaN, not a number). But you can use the pandas Int64 instead, notice capital ‘I’. The type_dict is a python dictionary mapping the column names to the dtypes.\n",
      "Sources:\n",
      "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
      "Nullable integer data type — pandas 1.5.3 documentation\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: Google Cloud BigQuery Location Problems\n",
      "answer: When running a query on BigQuery sometimes could appear a this table is not on the specified location error.\n",
      "For this problem there is not a straightforward solution, you need to dig a little, but the problem could be one of these:\n",
      "Check the locations of your bucket, datasets and tables. Make sure they are all on the same one.\n",
      "Change the query settings to the location you are in: on the query window select more -> query settings -> select the location\n",
      "Check if all the paths you are using in your query to your tables are correct: you can click on the table -> details -> and copy the path.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is very general: 'what do I need to do to be successful at module 1?' To provide a helpful answer, I need to understand what 'success' means in the context of module 1. This likely involves understanding the learning objectives, assessment criteria, and available resources. Therefore, I will search for information related to module 1's objectives, assessments, and resources.\", \"keywords\": [\"module 1 objectives\", \"module 1 assessment\", \"module 1 resources\", \"module 1 success tips\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The previous search returned only module-specific error messages from various modules, not general information about Module 1. I need to refine my search to focus on general success strategies, common challenges, and key topics covered in Module 1. I will search for information about the key topics and potential difficulties in Module 1 to provide more specific advice.\", \"keywords\": [\"module 1 key topics\", \"module 1 common problems\", \"module 1 difficulties\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"Unfortunately, I don't have specific details about the content of Module 1 to give you tailored advice. However, in general, to succeed in any module, it's helpful to: Review the module objectives to understand the key learning outcomes. Familiarize yourself with the assessment criteria to know how your work will be evaluated. Make use of the recommended resources, such as readings, videos, and practice exercises. Identify the key topics covered in the module and focus your study efforts accordingly. If you encounter difficulties, seek help from instructors, teaching assistants, or fellow students.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "178c316d-3064-40bf-943f-7d3830cb0a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "470126e3-4143-423b-bda9-f97a03300126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to call: search\n",
      "Arguments: {'query': 'how to succeed in module 1'}\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# Define the function declaration for the model\n",
    "search_tool = {\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Searches the FAQ database.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "tools = types.Tool(function_declarations=[search_tool])\n",
    "config = types.GenerateContentConfig(tools=[tools])\n",
    "\n",
    "def llm(prompt):\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        contents=prompt,\n",
    "        config=config\n",
    "    )\n",
    "    return response\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and your task is to answer it.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = prompt_template.format(question=question)\n",
    "\n",
    "response = llm(prompt)\n",
    "\n",
    "# Check for a function call\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    print(f\"Function to call: {function_call.name}\")\n",
    "    print(f\"Arguments: {function_call.args}\")\n",
    "    #  In a real app, you would call your function here:\n",
    "    #  result = schedule_meeting(**function_call.args)\n",
    "else:\n",
    "    print(\"No function call found in the response.\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fa29eb6-5485-446e-8248-9658b4435ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(id=None, args={'query': 'how to succeed in module 1'}, name='search')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "121cbbef-ea35-4a57-86b8-f9e3fc757484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.genai.types.FunctionCall"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(function_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5bd4cd03-11ba-402d-9401-e04f71d6b99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "06501ccd-f2ec-4438-8d36-3bab6f02e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5d617bc-d8ec-448c-a463-b28a1f0b3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = function_call.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57bdfda9-fdf9-497e-a483-860284a37e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how to succeed in module 1'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "02ff8e3c-1e1d-450f-af7b-0412ac457dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c2f5ebe-a848-4031-8a91-98835ff248fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = f(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e7c116e-e8bb-4b4b-8660-9abe3e2ac778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have information on general tips for success in Module 1. My search results for \"how to succeed in module 1\" returned specific technical solutions for common errors encountered in Module 1, such as issues with `psycopg2` or `SQLAlchemy`.\n",
      "\n",
      "If you are encountering a specific problem or error in Module 1, please let me know and I'll try my best to help you troubleshoot it.\n"
     ]
    }
   ],
   "source": [
    "# Create a function response part\n",
    "function_response_part = types.Part.from_function_response(\n",
    "    name=f_name,\n",
    "    response={\"result\": results},\n",
    ")\n",
    "contents = [\n",
    "    prompt\n",
    "]\n",
    "\n",
    "# Append function call and result of the function execution to contents\n",
    "contents.append(response.candidates[0].content) # Append the content from the model's response.\n",
    "contents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n",
    "\n",
    "final_response = gemini_client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=config,\n",
    "    contents=contents,\n",
    ")\n",
    "\n",
    "print(final_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "487df4a7-964f-498a-a233-5ac1cefb1bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=b'\\n\\xc9\\x04\\x01T\\xa8\\\\\\xee#,\\x96\\x8df\\x18n\\x1b\\x14\\xa3\\xaf\\x1e\\xfd\\x11c\\xb96f\\x8e\\x05/\\x8b\\xea`\\xa9\\xa8\\xe5\\x16\\x86c\\xcaE\\xca\\xdc\\x87\\xef^\\xef\\x1e\\xa8\\xf2\\xf0\\x7fr\\xe7L\\x86Gf\\x88+,\\x8f\\x12\\xe8\\xf5v\\xd6\\x95\\x84\\x84\\xf9\\xc2\\xe0J<\\x92>\\x1ftV\\xbc\\xd0F\\x9a:\\x8c\\xd9\\xe7\\x11\\xad\\x04\\xfc\\x0enH~d\\x95\\xc7\\x0c\\xa7\\x16n\\xb4\\x05wyK\\xca\\xad]C\\x80m\\xd1\\xbc\\x17R-\\xa3f\\xb3?\\xa1\\xc9d$\\xef\\x10t\\x01\\x05s\\xd78@\\x027=\\xcaMlV\\x1f<\\x8e\\x9b\\xb0\\x16\\xd6lu\\x86\\x92\\xa9\\xd1\\xf9\\x0c\\xadpks\\xf1-\\x7f$\\xab\\x9c\\r\\xa8{\\xc5\\x0b\\xf66\\xc7A|>\\x00\\xb5Z\\xcf\\xb5H^\\xedL1\\xf7\\xc6 \\xe2\\r\\xfa\\xd36\\x18\\xe0(\\xf6\\x1a^8nZ\\xf8\\x91.\\x85\\xd8\\x0c\\xf7@.&%\\xdd@\\xa0\\xe2\\x86\\xfe\\x98\\n\\x02\\xba|\\xfa\\xfd\\xfcs<QS\\xca\\x98<\\x895a$\\xa2LL\\x9e\\xee\\xef\\xc9;\\x87\\xda\\xac\\x12\\xae\\xc1\\x0e+\\x7fjP{u\\x16v\\xab\\x1c\\x9fh,\\xe0\\x93\\x18 m\\xdd!\\x82@\\xceX\\x87\\xac\\'\"\\xfbQxbD\\r|\\xe4\\xe8\\xe5\\xf1\\xder\\xc59\\x12w#\\xd06\\x9b\\xb4JWm\\nJ\\x98;\\x1f\\x1bwtm\\xe6\\xbe7\\x8a\\xf4t\\xd0c\\x95\\xe2\\n\\xc2\\xe1\\xdc\\x08\\r\\xcd\\xae(b\\xb3\\x89\\xbc\\x9dZ\\x11\\x01\\x1a\\xd1\\xb3V\\xd0\\xb7\\x0f\\xe5\\x00\\xbe\\x83\\xcb NGb\\xec\\xa1\\x84\\x924$\\xd1\\xa1]i\\xc9,\\xf7\\xcag\\x8d\\xbe\\x17[\\xf5\\xd7\\t{\\xe3\\xe8\\xc9\\x0ev\\xa7\\xfdX\\xa8_\\xe4\\x95\\xe6\\x1b;\\xb5EMM28\\xd0\\xe1H\\xf6k:\\xf7\\xa5\\x9e\\xc0\\x82\\xf7\\xf38\\xb2\\xef\\xbf\\xa0\\xa3\\xea\\xf1^d\\x89\\xdelk\\xf2\\xfaX\\xb5\\x97\\x01+\\xdc\\x18\\x06E\\xd0\\x1a\\xaeCO\\xc2\\x93n\\x99\\x84Z\\xc6\\xf7\\xa9\\x9d,%\\xa6P{|\\x05\\x9di\\xfa\\x9d4Y\\xf0\\x9f\\xe0\\x82vjMH\\xb3\\xbc\\x93#3B\\xcb=\\x12\\xd1\\xbaf\\xde\\xc1\\xcf\\xb4\\xe9^\\xbfZ8\\xdd\\x94o`\\xb8\\xea\\xe1\\r\\x16J\\x8aE\\x8d\\xb3\\x1b3X\\\\)\\xe9\\x07~{X\\xf5\\xd3\\xdc\\xef\\xfa\\xc0V\\xed\\x8c\\x10\\xa0\\t\\xf8E\\xe0\\xdc\\xb0\\xec6\\xc7\\xd8\\xa2\\xa0\\x17j\\xd0\\x877\\x0e\\xf2\\xdadG\\xc6)9R\\rLz\\xd7x\\xc7V\\xf3j\\xdf\\x99qH\\xf28\\x0b$\\xb4\\xd1\\xa4|M\\x08\\xce\\xee\\x88\\xe0', code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='I don\\'t have information on general tips for success in Module 1. My search results for \"how to succeed in module 1\" returned specific technical solutions for common errors encountered in Module 1, such as issues with `psycopg2` or `SQLAlchemy`.\\n\\nIf you are encountering a specific problem or error in Module 1, please let me know and I\\'ll try my best to help you troubleshoot it.')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=None, grounding_metadata=None, index=0, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.5-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=88, candidates_tokens_details=None, prompt_token_count=1232, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1232)], thoughts_token_count=114, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1434, traffic_type=None) automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8e890658-8e1a-4c79-b2b3-58f82fa3b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function to call: search\n",
      "Arguments: {'query': 'success module 1'}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and your task is to answer it.\n",
    "\n",
    "If you look up something in FAQ, convert the student question into multiple queries.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = prompt_template.format(question=question)\n",
    "\n",
    "response = llm(prompt)\n",
    "\n",
    "# Check for a function call\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    print(f\"Function to call: {function_call.name}\")\n",
    "    print(f\"Arguments: {function_call.args}\")\n",
    "    #  In a real app, you would call your function here:\n",
    "    #  result = schedule_meeting(**function_call.args)\n",
    "else:\n",
    "    print(\"No function call found in the response.\")\n",
    "    print(response.text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52f6c977-9925-40a7-ac89-571da878204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calls = [part.function_call for part in response.candidates[0].content.parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d0ed98d2-9f63-425a-854c-b97b870e10d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FunctionCall(id=None, args={'query': 'success module 1'}, name='search'),\n",
       " FunctionCall(id=None, args={'query': 'module 1 tips'}, name='search'),\n",
       " FunctionCall(id=None, args={'query': 'module 1 requirements'}, name='search')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eec136f6-2bba-4d78-a577-69d4b51e77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [\n",
    "    prompt\n",
    "]\n",
    "\n",
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name\n",
    "    arguments = tool_call_response.args\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    result = f(**arguments)\n",
    "\n",
    "    function_response_part = types.Part.from_function_response(\n",
    "        name=f_name,\n",
    "        response={\"result\": result},\n",
    "    )\n",
    "\n",
    "    return function_response_part\n",
    "\n",
    "parts = []\n",
    "for call in function_calls:\n",
    "    function_response_part = do_call(call)\n",
    "    parts.append(function_response_part)\n",
    "    \n",
    "# Append function call and result of the function execution to contents   \n",
    "contents.append(response.candidates[0].content) # Append the content from the model's response.\n",
    "contents.append(types.Content(role=\"user\", parts=parts)) # Append the function response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f08f6-6551-4388-80a6-fb27322630b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b70f4e5b-78a5-4f36-937a-d793c09265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I couldn't find any specific information about general success strategies or requirements for Module 1 in the FAQ. The search results mainly provided solutions for technical issues encountered in Module 1, such as \"ModuleNotFoundError: No module named 'psycopg2'\" or \"TypeError: 'module' object is not callable\" when working with Python and SQLAlchemy.\n",
      "\n",
      "If you are encountering a specific technical problem in Module 1, please let me know and I can try to find a solution in the FAQ.\n"
     ]
    }
   ],
   "source": [
    "final_response = gemini_client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=config,\n",
    "    contents=contents,\n",
    ")\n",
    "\n",
    "print(final_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909fba6-98ef-4757-944e-89c9cd987f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d180a35c-6ed0-4b0c-bbe9-9f91b65907de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_metadata=None thought=None inline_data=None file_data=None thought_signature=b\"\\n\\xe7\\x05\\x01T\\xa8\\\\\\xee\\x08!5o \\xc4U\\xe1q\\x8d@?\\xa6j\\xaa\\xf9\\xa9\\x06\\x1boUw_\\xd4\\xccM\\x9f;\\x15\\xd6S\\xd6\\xe4\\x97\\x9c\\x04\\xab\\xa9\\xef\\xea\\xff\\xc9j=*\\xe6Bc\\x06U\\x13\\x9e\\x89\\x8d\\x9cb)\\xf3\\xa0:\\xc8\\x00\\xa4Q:\\xf7\\xf0\\xec|>\\xdf\\xdf\\x83u\\x92%#\\x9e\\x98\\x82`7^3\\xf6\\xd9)\\x1c\\xc4\\xc6\\xd1\\xeb\\xcf\\xa3c\\x1d\\xc7<\\x83\\xd7\\x90\\x1d\\x9dK\\x84u\\x1f\\x1c0\\xe9\\x82\\xb0d\\x1f-&\\xbb\\xb1E\\x15H3\\xfb\\xf0TV(\\xab\\xeaYec\\xe9\\xa7\\xb8\\x9cy\\xd0\\x05\\xf2\\x19b*\\xa2\\xa7&\\x8fJJ\\xdc\\xd9\\xe0\\x17\\x1d\\xaa\\x96\\xc9}g\\xb0\\xf3\\x95\\x98\\xf6\\xa6<\\x9aq\\x87\\x9au\\x83\\xdbX\\xd8\\xe5juX\\xd7\\x9b\\xfbU\\xc5ZG\\x02\\x00\\xb2\\xa4z#\\x18\\n\\x02\\x90\\xd0\\\\\\xe2t\\xd6mL\\x01\\xfbX\\xbc\\x8fd\\xf4\\xd1&\\xe7f}\\x7f'\\xcb\\xabnMf\\xaePpm@j\\xff\\xa5\\xe9\\xeda\\xe0\\xdah\\x10ZB2\\xd3zGz\\xff\\xc6\\xbf\\xbaoA\\xc3`\\x05\\xdb\\x1b\\x05\\xf4}@_\\x1e\\x87\\xba\\xb3\\x06\\x993\\xd2\\xe1\\xd8,\\x8a;\\x17?\\x87\\x0b\\xbf\\xb4F\\xb6f\\xa4\\xbe\\xa3\\xee\\x17\\x88\\xfa\\x10$\\xf8\\x1b\\xbf\\x88q+\\x83\\x1f\\x9c\\x0b\\xbep\\xea\\xac4%W\\xdb\\xe9jDx\\xcf/\\x05l\\x14%\\xceHiiu\\xebN[\\x1f@\\xa4#_!\\t\\xd3\\xaa\\x10\\x94L\\xa2\\xc1\\xd5\\xe3\\xe5Wn\\x0f\\\\\\xe1R\\xfb\\xd9\\n[+\\x11$TpEM{A\\xcb\\xf02\\xb82$d\\xd1-OVFV9\\xf7N\\xb5\\xe6\\x7f\\xa9Ju\\xa2\\xd5\\x10\\xbcR\\xdc\\xae\\x9d\\x7f\\xe0\\xcfR\\x85\\x8b\\x19\\x1b|dm\\xabJ\\xd6K\\x8b\\xe2\\x13\\x82\\xbe\\x8f[\\x87\\xcd\\xfb\\x1c\\xee|\\xc5\\x0eb\\xb1\\rA\\x1b\\xd39\\xf6m\\xfb\\x9cT\\xbb\\x94\\xfb\\xdf\\xc4|\\xa8q\\xbac\\xe4~\\x13=&'\\xa0\\x01$\\x84\\xea6I\\xb7\\x13h\\xe2>\\x17\\xd6\\xf2\\x9c\\xe7\\x8f\\xcbM\\x84\\xe0\\x085.\\xc2E\\xcc\\xe4\\x96I\\x04\\x98\\xdfh\\xdd(\\x01\\xcb\\xf5i\\x10\\xa4\\xddM\\xf2\\xb1\\xc5\\x86N\\xb5\\xedUO\\xfcf\\x9b\\x0bmBuY\\xad\\x0c\\xaa\\xbc\\xcd\\xc8\\x88\\xc2lZ\\x9akL\\x82E\\x1a\\xa5\\x88g\\t\\xad\\xce\\xb3\\xa0qN>z\\xb6\\xe8\\x9c\\xaau\\xcf\\x03\\xe0E\\xc0\\x0e7\\xd91byy\\x92\\x1d\\xd8V.\\x08}\\xb5\\xa6\\x8b\\xa1SQ\\x1a\\x0c\\xfb}\\x97\\xf6j\\x1c\\xcd\\xa4\\xbd\\xf0\\x91\\xd2k\\xf0\\x0boA\\xa0zq\\x969@\\xe1xQi\\x08\\xc0\\xd1/\\x8bi;\\x0c>\\x95\\x12\\x1ekC\\xf5\\x832\\xe8\\x99|:|\\xeb\\xdb\\x8d\\x0c\\xfb\\x17 6\\x9a\\x95\\x11\\xb3*\\xa4\\x024\\x9a\\xf7\\xda\\xd8x\\x99p\\xffNuE\\xbe\\x8d\\xbd\\xc7\\x8e\\xe9\\xa0\\x9c]\\xfawP\\x8c\\x1c\\x9e\\x1b\\x97\\x80\\x83\\xa4^~\\x17\\x10\\xce\\xe9-7\\xf3F\\x8e\\xb95\\xfc/\\x1e\\n\\t%\\xde\\xe7\\x17\\xc7\\xdf\\xbaj\\x0b\\x10;\\xb5\\xc8\\xf7>\\x199\\xe1%Y\\x08\\xaa\\xd50\\xd2T\\xafZ\\x84\\xb3\\xa2Q{O\\xffca\\x19a\\xb0\\xea0S^\\xe5\\x85gt\\x9eW^\" code_execution_result=None executable_code=None function_call=None function_response=None text='I\\'m sorry, I couldn\\'t find any specific information about general success strategies or requirements for Module 1 in the FAQ. The search results mainly provided solutions for technical issues encountered in Module 1, such as \"ModuleNotFoundError: No module named \\'psycopg2\\'\" or \"TypeError: \\'module\\' object is not callable\" when working with Python and SQLAlchemy.\\n\\nIf you are encountering a specific technical problem in Module 1, please let me know and I can try to find a solution in the FAQ.'\n",
      "I'm sorry, I couldn't find any specific information about general success strategies or requirements for Module 1 in the FAQ. The search results mainly provided solutions for technical issues encountered in Module 1, such as \"ModuleNotFoundError: No module named 'psycopg2'\" or \"TypeError: 'module' object is not callable\" when working with Python and SQLAlchemy.\n",
      "\n",
      "If you are encountering a specific technical problem in Module 1, please let me know and I can try to find a solution in the FAQ.\n"
     ]
    }
   ],
   "source": [
    "for entry in final_response.candidates:\n",
    "    contents.append(entry.content.parts[0])\n",
    "    print(entry.content.parts[0])\n",
    "\n",
    "    if entry.content.parts[0].function_call:      \n",
    "        result = do_call(entry.content.parts[0].function_call)\n",
    "        contents.append(result)\n",
    "    elif entry.content.parts[0].text:\n",
    "        print(entry.content.parts[0].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5124f30a-5933-45c2-828e-e70e22ae5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f1818eb7-5e49-4912-8696-b11515930d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt_template = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "153f3a76-77cd-41f7-b6d3-1bd013bc165a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"You're a course teaching assistant. \\nYou're given a question from a course student and your task is to answer it.\\n\\nUse FAQ if your own knowledge is not sufficient to answer the question.\\nWhen using FAQ, perform deep topic exploration: make one request to FAQ,\\nand then based on the results, make more requests.\\n\\nAt the end of each response, ask the user a follow up question based on your answer.\\n\\n<QUESTION>\\nwhat do I need to do to be successful at module 1?\\n</QUESTION>\"]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "02a9b9a9-d886-4479-b8d6-8ad02d0c28a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " how do i do well in module 1?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function_call: content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=b'\\n\\xb5\\x04\\x01T\\xa8\\\\\\xee=\\xeb\\xef.\\xe7B<\\x87\\xa2\\xab$4\\xceD\\x03\\xeeM\\xddd\\xfd\\xb4\\xf4;\\xe7\\xa0\\xcbN/<\\x91\\xe3.,\\xb8\\xf8\\xa1|\\x02\\xe8\\xfc\\x05\\xb4\\xeeD\\xfd\\x03\\x9aV\\xa0\\x03\\xce\\x8d\\x97\\x9f\\t\\xf0\\x85\\xd19\\x9b\\xa0\\xa7\\xa3\\xb19\\xc3?\\x93\\xbb\\x85\\xb8\\x80\\xa7J\\x15\\x80\\xd9{|\\xdb\\xb8\\x92\\x00fkH\\x9b)\\xa7\\xc40\\xbf8\\xee\\xef~3l\\xdf\\x0e\\xd9J\\xe3\\xd4v`f\\x83 \\x88\\xe6\\xf3\\x85\\x8c\\xbdM\\xd6\\xd8\\xb2P\\xaa\\xd5i\\xcaVJ\\xc1\\x99\\x0e\\x88\\xe6\\xf1\\xf7\\xa7N\\xe0\\xe4\\x89\\x0f\\x81\\xc3`\\xd2\\x86\\xc4\\x9c\\xe8\\x02\\r3t\\x1aQ\\x0fx%\\x90\\xb0ic\\x0b\\xd1\\x83e\\xde\\xb4\\xae\\xecOX5\\x1fJLW\\xb4(G\\x05\\x10\\x07\\x93M\\xdeg\\xbb\\xc4\\x965^\\x8c?\\x1c\\x99\\x1ak\\x12I\\xc4.\\x1a\\x87\\xe7O\\x1dG\\xa7\\xf5\\xfa\\xf4\\x03\\xbbX\\xaff,a\\xcf)w\\x8d\\xb2\\x926\\xef\\xab\\xc6|\\x9d|\\xaa\\xd4<Jb\\x93\\x88\\xf1\\x83\\xe1\\x7f\\x93\\xf8#\\xb4V\\xbfX\\x87o\\xf2W\\x1f#\\xae\\x91\\x00)d\\xe5z\\xc4\\x83\\x16\\x1d`\\xef>\\xb8\\x9f[\\xfb\\x9a\\xb4\\xc0\\xe0\\xf1Q\\xbby\\xb8\\xe9G}\\x03Eq\\xc3\\x8a_\\x0el~7\\x9e\\x8d\\xbc\\x8b\\xe8\\x9d\\xa4\\x0bU\\x1f]Q~\\xf4\\x9b>\\xa1\\x80\\xe7\\x90\\xa0t\\xf5\\xe5\\x88\\xf4\\x07<\\xd3\\xaa\\xcf\\x1c\\xbb\\xb0\\xd8\\xe0\\xfdm\\x8cN\\x1b\\r\\xc4\\x9b\\xf1d\\xe3#2DYr\\x8b\\x9a}\\xb4\\x13jkJ\"\\x89\\xe0\\x91\\xaf#\\xd6;k\\xdfh^\\x19\\xc7M\\x1c\\xc1`\\xaa\\x14\\xa1r\\x03y\\x96\\xa9$_%\\x0f\\x81L\\x0c\\x01\\x04\\x0c\\xc5UK\\x8b\\x89\\x11\\xe4M\\x82\\xb9@e@e\\x06\\xf1\\xf0\\xba\\x82\\xf7\"j\\x9f\\x86\\xc12[\\xc3\\x05\\xc7\\n\\xcaw\\x9e\\x9c\\xdc\\xdc\\x91s\\xe0\\xac@\\xd8\\xdc\\x94\\xd5\\x93\\xa4\\x10\\x16*\\xe4`\\x88\\r7\\x9fU\\x82(\\xebI-\\x01j\\xc1~Z|E(\\xb0\\xc5 .\\xbd4\\r(\\xc0\\x15\\xd1\\xcf \\x92\\x89\\xc0hk\\xcf\\xe4\\x0f\\xad\\x07\\xa8U\\xda\\xbe\\x03\\xe7\\x80A\\xbf\\xd8\\xe5\\xf0f\\xfe\\x00\\xf8W\\x7f\\x05Ce\\xe4o+D2\\xc7\\x08x\\x1d\\xb8\\xfa\\xb5_^\\x8f\\x1b\\x182\\x12\\xc1d\\xee\\xcd\\x0f\\xf4\\xbf\\x01\\xf0\\x05\\x08\\x08\\x1c\\xd6!\\x1ckO\\xe1\\xbc\\xe7\\xa9\\xaf=1\\x97\\xf0\\x08\\xbc\\x98X\\x9dK\\x0f\\xd8`', code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'query': 'how to do well in module 1'}, name='search'), function_response=None, text=None)], role='model') citation_metadata=None finish_message=None token_count=None finish_reason=<FinishReason.STOP: 'STOP'> url_context_metadata=None avg_logprobs=None grounding_metadata=None index=0 logprobs_result=None safety_ratings=None\n",
      "\n",
      "While the FAQ primarily addresses technical issues, Module 1 generally focuses on Docker and Terraform. To do well in Module 1, I recommend the following:\n",
      "\n",
      "1.  **Understand the Core Concepts:** Make sure you grasp the fundamental ideas behind Docker (containers, images, Dockerfile) and Terraform (infrastructure as code, providers, resources).\n",
      "2.  **Practice Regularly:** Hands-on experience is crucial. Work through all the provided exercises and try to build your own small projects using Docker and Terraform.\n",
      "3.  **Review the Material:** Go over the lecture videos, notes, and any supplementary readings multiple times to reinforce your understanding.\n",
      "4.  **Ask Questions:** If you encounter any difficulties or have doubts, don't hesitate to ask for clarification in the course forum or during office hours.\n",
      "5.  **Troubleshoot Actively:** When you face errors, try to understand the error message and debug it yourself before seeking help. This builds strong problem-solving skills.\n",
      "\n",
      "Are there any specific topics in Module 1 that you're finding challenging or would like to know more about?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I need help with docker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "function_call: content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='\\n'), Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=b'\\n\\xd1\\x03\\x01T\\xa8\\\\\\xee\\x1f\\xc9\\\\\\xff\\xc0\\xc9\\xc5\\xeb=<\\x9b\\xdbtn\\xc6V\\xa5\\xa5\\xf3\\xcb~x\\xd2\\x89\\x0e\\x02\\xe6\\xfd\\x10a\\t\\x0b\\x07\\xb1\\x87\\x04c\\x9c\\xd4\\xdfq\\xb0A<On\\xcb\\xf2\\xddy\\xe5x\\xff\\xf8[\\xe9\\xa1m\\xd1\\x012\\xaah\\xb00|\\x11F\\xa0\\xaf\\xc3\\xaf\\xddO6\\xd6(I\\x9c\\xecN\\x13\\xf4\\x9fn\\xfa\\xf3&]\\xb8\\xca\\xad\\x11y\\x8a\\x08\\xd1G\\x0c\\xae.\\xec\\xf2\\x91\\x84+\\xc7\\xb2m\\xc7/\\xaaX8F\\xee\\x12\\xfd\\x81\\xc6Hj\\xd4\\xbeO\\x1fE>t\\xc7?\\xe0\\x1f\\x0f\\xfe\\xe8\\x90\\xb7=\\xb6s\\x14;S\\xb9\\xde\\x1e,g\\x96H_\\x87:3PR\\xbfx\\xc0\\x925(\\xfd\\x01P\\xf2\\xee\\xc9\\xbf\\xcde;|\\x07k\\x13\\x96X\\x13\\xb0\\r\\xb9\\xfa\\x10\\xbai*\\xc8a\\x89\\xc1\\xe1\\xcf\\xc6%*\\x07K\\x9f<\\xc2\\x13\\xdf\\x11\\xfeI\\xab\\xba\\xe2\\xf4\\xff\\xca\\xaf\\xba\\xc7\\x89\\x08D\\xc4\\xa1\\xd3:F\\x1f\\xf8R\\x86POK\\xc7\\x9c8f\\xbb\\x04\\xbe\\xe0{\\xaf\\xff{\\x902Dn\\xbe\\xfe\\xff\\xa3\\xc4\\xe8{;i\\xf1\\xf3\\x1f\\xbb\\xbe\\x13\\x1f\\xda\\xbe\\x9essyp\\xbc\\x03<\\x9a\\xd5\\x94\\xd0\\x00{<j9z^\\xa7\\n\\xcae\\xae\\xe3/ \\x86H\\xe1\\t\\x00\\xbf)\\xb9\\x81R\\x86o\\xdf\\xff\\x07\\xcc\\x87\\x9e\\x1a\\x19<0S\\x9b\\xc9)\\xd6\\xd8h\\x07\\xe3\\xb9\\xdeW1m\\xd2\\xe4\\x15kH\\xdf9)\\x07P)\\x9c\\xb2\\xd6|^#\\xe77\\x83\\xfa\\xfe(*sxC\\xe7\\x11\\xd2Dt\\xb1\\x8fO\\xe8\\xfe\\xca\\x8e\\x01\\x93\\xd0\\xe0R\\x14\\x8e\"m\\x8d\\x7fM7\\x15V\\x13\\xa1Ymcs\\xd9\\x9c\\x04S\\x84z8\\x1f0V\\xd0\\x0b\\xe8s\\xa6q!\\xa9\\xd7\\xefyL\\x01\\xe7\\x80\\x86*\\xc0\\xb1\\x03=\\xa9\\x07lP\\xdb[8\\x1b\\x8e\\x04\\x85\\x1c\\xc2\\x1a\\x8a\\x19\\xac,\\x98\\xd3\\xcc\\x0c\\x02\\xe3\\xcfmA,\\xe5\\xab|\\xb3\\x84\\xb1\\xf6\\x07\\xcb+!\\x00\\x08', code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'query': 'docker'}, name='search'), function_response=None, text=None)], role='model') citation_metadata=None finish_message=None token_count=None finish_reason=<FinishReason.STOP: 'STOP'> url_context_metadata=None avg_logprobs=None grounding_metadata=None index=0 logprobs_result=None safety_ratings=None\n",
      "\n",
      "Docker is a broad topic, and the FAQ has several entries related to common Docker issues. To help you best, could you please specify what kind of help you need with Docker? For example, are you facing issues with:\n",
      "\n",
      "*   Installing or starting Docker?\n",
      "*   Running a specific Docker command (like `docker pull` or `docker run`)?\n",
      "*   Understanding Docker concepts like images, containers, or volumes?\n",
      "*   Troubleshooting an error message related to Docker?\n",
      "\n",
      "Please provide more details about the problem you're encountering.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I need help starting docker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "function_call: content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='\\n'), Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=b'\\n\\xbe\\x02\\x01T\\xa8\\\\\\xee\\x80\\xc1S\\x93\\x85RUn\\x9d\\x89\\xab\\x7f\\xb5\\xc9,uF\\x01\\xf2\\xfb\\xfd|\\x98&3\\xc2\\xb0\\\\\\xb0H,czl\\xa7\\x14\\x7f\\xc7\\x8a0\\x9d\\xc8W\\x88\\x113\\xcc=\\xeb\\xc3\\xf04\\x9f\\xda\\xfe\\xbeM&\\xbf\\x03\\xf2\\xfd\"\\x01\\x9a\\xd1\\xe9\\x0b\\xa9)#\\xee\\xb8\\xff\\x01I\\x99\\x07\\xdd\\x03\\xd4\\x91\\xab\\xd8*u\\xccq\\xd9\\xc4\\xcd\\t\\xb4H\\x99\\x19Z!\\xd3WGztN\\x9b7\\xe3I%\\xc1\\xc1\\x9a\\xf2\\xde\\xbdv\\x19\\xff\\x02\\xc4[\\x82kY\\x90\\xdd\\xc8m\\xf3\\xef\\xf0tX\\xa1\\x9an\\xb6\\x00\\xe9\\x15Cm\\t\\xd9\\x1f\\xb7\\xc5\\xec\\xd72 1\\xad\\x99\\xa1\\x1f\\x90\\xc8^\\x10w\\xee\\xd4_cI\\xc5\\xc1 \\xdd\\xec4\\x0f9\\xc5u\\x14\\xf5\\x15\\x12\\xa6\\xc8\\xb4\\xcd\\xe2V\\xf9Cr\\xe8\\x05\\x7fs\\xbaR_p\\x17* !\\xd5\\xa0\\x06\\xe5i\\xb1\\'\\xb3\\xc5\\n0\\x0exZO\\xbb\\x82\\xd6\\x92T\\xaf\\xe5\\x02\\xe2A\\xd7g nv\\xf5\\xd2\\xc0\\xd6\\x9f\\x0cH\\xf48\\xd1\\xf9~\\xa4h\\x9aJ\\xe9\\xe6{\\xc8:t\\xaa>\\x1d\\x96)N\\x17\\xc5B\\xb9\\x1c\\xe1`Q\\xf5\\x9f\\xef\\x97Py\\\\\\x1fx;\\xf0\\x9a\\xd2\\x1b~\\x19\\x0c\\x92\\xc2\\x14\\xaf\\xd36\\xb0\\x17\\x07\\xc6\\xefqK\\xa1\\xd1\\x93\\xff\\xca\\x96t!\\xf9\\x11\\xb4Q\\xc1\\xaa\\xd1\\xb8', code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'query': 'starting docker'}, name='search'), function_response=None, text=None)], role='model') citation_metadata=None finish_message=None token_count=None finish_reason=<FinishReason.STOP: 'STOP'> url_context_metadata=None avg_logprobs=None grounding_metadata=None index=0 logprobs_result=None safety_ratings=None\n",
      "\n",
      "It sounds like you're having trouble getting Docker to start. There are a few common reasons why this might happen, and here are some solutions based on frequently asked questions:\n",
      "\n",
      "1.  **Docker is stuck or won't start on Windows (Windows 10/11):**\n",
      "    *   **Update Docker:** Ensure you're running the latest version of Docker for Windows. Sometimes, upgrading through the menu doesn't work, so a clean uninstall and reinstall might be necessary.\n",
      "    *   **Switch containers:** Try right-clicking the Docker symbol in your running programs and switching containers between Windows and Linux, or vice versa.\n",
      "    *   **Hyper-V/WSL2 Backend:** If you're on Windows 10/11 Pro, ensure Hyper-V is enabled. If you're on a Home version, or prefer WSL2, make sure WSL2 is properly configured and updated.\n",
      "\n",
      "2.  **\"Error starting userland proxy: listen tcp4 0.0.0.0:8080: bind: address already in use\"**:\n",
      "    *   This error means another service is already using the required port (e.g., 8080). You can stop the process using that port by running:\n",
      "        \n",
      "\n",
      "```bash\n",
      "        sudo kill -9 `sudo lsof -t -i:<port>`\n",
      "        ```\n",
      "\n",
      "\n",
      "        Replace `<port>` with the port number indicated in the error (e.g., 8080).\n",
      "\n",
      "3.  **Permission denied when stopping/restarting Docker service**:\n",
      "    *   If you encounter a \"permission denied\" error when trying to stop or restart Docker, you might need to restart the Docker service:\n",
      "        \n",
      "\n",
      "```bash\n",
      "        sudo systemctl restart docker.socket docker.service\n",
      "        ```\n",
      "\n",
      "\n",
      "\n",
      "4.  **Cannot install Docker on MacOS/Windows 11 VM on Linux (Nested Virtualization)**:\n",
      "    *   If you're running Docker within a virtual machine on a Linux host, you might need to enable nested virtualization. Before starting your VM, run the appropriate command for your CPU:\n",
      "        *   **Intel CPU:**\n",
      "            \n",
      "\n",
      "```bash\n",
      "            modprobe -r kvm_intel\n",
      "            modprobe kvm_intel nested=1\n",
      "            ```\n",
      "\n",
      "\n",
      "        *   **AMD CPU:**\n",
      "            \n",
      "\n",
      "```bash\n",
      "            modprobe -r kvm_amd\n",
      "            modprobe kvm_amd nested=1\n",
      "            ```\n",
      "\n",
      "\n",
      "\n",
      "Could you tell me if any of these situations apply to you, or if you're seeing a specific error message when trying to start Docker?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " stop\n"
     ]
    }
   ],
   "source": [
    "chat_messages = []\n",
    "# Define the function declaration for the model\n",
    "search_tool = {\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Searches the FAQ database.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "tools = types.Tool(function_declarations=[search_tool])\n",
    "config = types.GenerateContentConfig(tools=[tools])\n",
    "\n",
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    chat_messages.append(developer_prompt_template.format(question=question))\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            config=config,\n",
    "            contents=chat_messages,\n",
    "        )\n",
    "        #print(response)\n",
    "\n",
    "        has_messages = False\n",
    "\n",
    "        for entry in response.candidates:\n",
    "            for part in entry.content.parts:\n",
    "                chat_messages.append(part)\n",
    "            \n",
    "                if part.function_call: \n",
    "                    print('\\nfunction_call:', entry)\n",
    "                    print()\n",
    "                    result = do_call(part.function_call)\n",
    "                    chat_messages.append(result)\n",
    "                elif part.text == '\\n':\n",
    "                    print(part.text) \n",
    "                    has_messages = False\n",
    "                elif part.text:\n",
    "                    print(part.text) \n",
    "                    print()\n",
    "                    has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bfe29d-9166-4eb5-8b21-4628ec67887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f2ffcdda-46bf-43be-be1a-20dfd6420b75",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'markdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[171]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchat_assistant\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/llm-zoomcamp/0a-agents/chat_assistant.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmarkdown\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTools\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'markdown'"
     ]
    }
   ],
   "source": [
    "import chat_assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bd90b6d7-d03d-4b17-8168-abb0e059bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: markdown\n",
      "Successfully installed markdown-3.8.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f0e17f35-48d1-4918-872f-5939f8dc7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chat_assistant6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "28ce12bc-4825-49f9-afff-87b655bbfcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search',\n",
       " 'description': 'Searches the FAQ database.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'type': 'string',\n",
       "    'description': 'Search query text to look up in the course FAQ'}},\n",
       "  'required': ['query']}}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a1b717ad-7c59-4bdb-b0f3-9a98ef815b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = chat_assistant6.Tools()\n",
    "tools.add_tool(search, search_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "47762605-cf27-4ae6-988c-6450facd8909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'description': 'Searches the FAQ database.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'Search query text to look up in the course FAQ'}},\n",
       "   'required': ['query']}}]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.get_tools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2a953a33-95d0-4136-b975-dd56264ff006",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0066b5e6-c7b1-4b09-9a95-04b1bd164b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_interface = chat_assistant6.ChatInterface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "519db801-a16d-4e5f-95db-0872d0180726",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = chat_assistant6.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=gemini_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0bf761-7b2a-481c-977c-5539eb952379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: how do i do well in module 1?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({'query': 'how to do well in module 1'})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>id=None args={'query': 'how to do well in module 1'} name='search'</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=None function_response=FunctionResponse(will_continue=None, scheduling=None, id=None, name='search', response={'result': [{'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', '_id': 299}, {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp', '_id': 322}, {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', '_id': 323}, {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp', '_id': 112}, {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\", 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\", 'course': 'data-engineering-zoomcamp', '_id': 125}]}) text=None</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well in Module 1, I recommend focusing on a few key areas:</p>\n",
       "<ul>\n",
       "<li><strong>Understand the core concepts:</strong> Make sure you grasp the fundamental ideas presented in lectures and readings. Don't hesitate to review materials if something is unclear.</li>\n",
       "<li><strong>Practice regularly:</strong> Module 1 often involves hands-on exercises or coding. Consistent practice is crucial for solidifying your understanding and developing practical skills.</li>\n",
       "<li><strong>Engage with the material:</strong> Actively participate in discussions, try out different approaches to problems, and don't be afraid to experiment.</li>\n",
       "<li><strong>Manage your time effectively:</strong> Break down the module content into manageable chunks and set aside dedicated time for studying and completing assignments.</li>\n",
       "<li><strong>Ask for help when needed:</strong> If you encounter difficulties, reach out to your TAs or instructors. We are here to support your learning.</li>\n",
       "</ul>\n",
       "<p>Do you have any specific concerns about the content or assignments in Module 1 that I can help clarify?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: please search the fax on the information how to do well in module 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({'query': 'how to do well in module 1'})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>id=None args={'query': 'how to do well in module 1'} name='search'</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>video_metadata=None thought=None inline_data=None file_data=None thought_signature=None code_execution_result=None executable_code=None function_call=None function_response=FunctionResponse(will_continue=None, scheduling=None, id=None, name='search', response={'result': [{'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", 'section': 'Module 4: analytics engineering with dbt', 'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\", 'course': 'data-engineering-zoomcamp', '_id': 299}, {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand', 'section': 'Module 5: pyspark', 'question': 'Module Not Found Error in Jupyter Notebook .', 'course': 'data-engineering-zoomcamp', '_id': 322}, {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.', 'section': 'Module 5: pyspark', 'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\", 'course': 'data-engineering-zoomcamp', '_id': 323}, {'text': \"Issue:\\ne…\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\", 'section': 'Module 1: Docker and Terraform', 'question': \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\", 'course': 'data-engineering-zoomcamp', '_id': 112}, {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\", 'section': 'Module 1: Docker and Terraform', 'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\", 'course': 'data-engineering-zoomcamp', '_id': 125}]}) text=None</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I've searched the FAQ database for \"how to do well in Module 1.\" The search results primarily cover troubleshooting specific technical issues that can arise within the module, such as \"Module Not Found\" errors for various Python packages.</p>\n",
       "<p>The FAQ doesn't contain general study tips or strategies for excelling in Module 1. However, based on general best practices for learning, here are some recommendations to help you succeed:</p>\n",
       "<ul>\n",
       "<li><strong>Understand the core concepts:</strong> Ensure you grasp the fundamental ideas and theories presented in the lectures and readings.</li>\n",
       "<li><strong>Practice regularly:</strong> Module 1 often involves practical exercises and coding. Consistent hands-on practice is essential for building skills and reinforcing your understanding.</li>\n",
       "<li><strong>Actively engage with the material:</strong> Participate in discussions, experiment with different problem-solving approaches, and don't be afraid to try new things.</li>\n",
       "<li><strong>Manage your time effectively:</strong> Break down the module content into manageable parts and allocate sufficient time for studying and completing assignments.</li>\n",
       "<li><strong>Seek help when needed:</strong> If you encounter any difficulties, please reach out to your TAs or instructors. We are here to assist you.</li>\n",
       "</ul>\n",
       "<p>Is there a specific topic or type of assignment in Module 1 that you're particularly concerned about?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738df2c-f051-4289-9128-d37d87bc9fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
